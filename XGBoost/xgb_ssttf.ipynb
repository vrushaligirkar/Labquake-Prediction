{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "xgb_ssttf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIIPsli8A2co"
      },
      "source": [
        "XGBoost model for predicting filtered shear stress and Time to next event (TTF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-UP5CXOLBwi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "from sklearn import multioutput\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "from xgboost import XGBRegressor, plot_importance\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import h5py"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX4nKxhn23ec"
      },
      "source": [
        "\n",
        "\n",
        "def create_timesteps(data, n_steps):\n",
        "\tx = []\n",
        "\ty = []\n",
        "\tfor i in range(len(data)-1):\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\tif end_ix > len(data)-1:\n",
        "\t\t\tbreak\n",
        "\t\tx1, y1 = data[i:end_ix, :-2], data[end_ix, -2:]  #last two columns are the target variables\n",
        "\t\tx.append(x1)\n",
        "\t\ty.append(y1)\n",
        "\treturn np.array(x), np.array(y)\n",
        " "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_qSE2WBLJMU",
        "outputId": "15b8e4a2-389b-4686-ebd5-e971d9b9fe02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the data\n",
        "\n",
        "data = loadmat('/content/drive/My Drive/Colab Notebooks/Labquake_prediction/MLpreprocessed_code/data/p5270_ML_Master.mat')\n",
        "\n",
        "m_t = pd.DataFrame({'Time':data['Time'].ravel().round(2), 'SS':data['SS'].ravel(), 'TTF':data['TTF'].ravel()})\n",
        "a_t = pd.DataFrame({'Time':data['LocalAcTime'].ravel().round(2), 'V_filt':data['V_filt'].ravel(), 'Vel_pc':data['Vel_pc'].ravel()})  \n",
        "df1 = a_t.merge(m_t, on='Time')\n",
        "\n",
        "data2 = loadmat('/content/drive/My Drive/Colab Notebooks/Labquake_prediction/MLpreprocessed_code/data/p5270_run1_pp_wAmp.mat')\n",
        "df2 = pd.DataFrame({'maxFreqI_filt':data2['maxFreqI_filt'][3787:136186].ravel(), 'freqQAmpI_filt':data2['freqQAmpI_filt'][3787:136186].ravel(),\n",
        "                    'freqQAmpI_filt_pc':data2['freqQAmpI_filt_pc'].ravel()})\n",
        "\n",
        "df = pd.concat([df1, df2], axis=1)\n",
        "\n",
        "df = df[['freqQAmpI_filt', 'freqQAmpI_filt_pc', 'V_filt', 'Vel_pc', 'maxFreqI_filt', 'SS', 'TTF']]\n",
        "print(\"Input data:\\n\", df)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:\n",
            "         freqQAmpI_filt  freqQAmpI_filt_pc  ...        SS  TTF\n",
            "0         31438.277060                0.0  ...  5.656166  0.0\n",
            "1         31421.341616                0.0  ...  5.657157  0.0\n",
            "2         31409.798761                0.0  ...  5.658317  0.0\n",
            "3         31398.815589                0.0  ...  5.659499  0.0\n",
            "4         31395.584981                0.0  ...  5.660404  0.0\n",
            "...                ...                ...  ...       ...  ...\n",
            "132394    31041.955345                0.0  ...  5.471059  0.0\n",
            "132395    31035.059531                0.0  ...  5.474545  0.0\n",
            "132396    31020.001291                0.0  ...  5.478286  0.0\n",
            "132397    31012.016780                0.0  ...  5.481751  0.0\n",
            "132398    31010.874482                0.0  ...  5.484813  0.0\n",
            "\n",
            "[132399 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeGpzDqI27pM",
        "outputId": "454a322e-f36e-4c81-833d-beb1a622c9bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "arr = df.to_numpy()\n",
        "n_steps = 300\n",
        "xdf, ydf = create_timesteps(arr, n_steps)\n",
        "\n",
        "print('Features shape, X = ', np.shape(xdf))\n",
        "print('Target shape, Y = ', np.shape(ydf))\n",
        "\n",
        "# Reshape features from 3D to 2D (for input layer)\n",
        "\n",
        "in_dim = xdf.shape[1]*xdf.shape[2]\n",
        "xdf = xdf.reshape((xdf.shape[0], in_dim))\n",
        "print('After reshaping, X = ', np.shape(xdf))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features shape, X =  (132099, 300, 5)\n",
            "Target shape, Y =  (132099, 2)\n",
            "After reshaping, X =  (132099, 1500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVVFwF-4ndyb"
      },
      "source": [
        "# Split into train-val-test\n",
        "x_train, x_test, y_train, y_test = train_test_split(xdf, ydf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.1, shuffle=False)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f77XYoWmrcb4"
      },
      "source": [
        "# Parameter tuning\n",
        "\n",
        "params = {\n",
        "        'learning_rate': [0.01, 0.1, 0.5],\n",
        "        'n_estimators': [200, 600, 1000],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 5, 7, 9],\n",
        "        'objective':['reg:squarederror']\n",
        "        }\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for g in ParameterGrid(params):\n",
        "  model = XGBRegressor()\n",
        "  model.set_params(**g)\n",
        "  model = multioutput.MultiOutputRegressor(model)\n",
        "  model.fit(X_train, Y_train)\n",
        "  y_predVal = model.predict(X_val)\n",
        "  val_r2 = r2_score(Y_val, y_predVal)\n",
        "  if val_r2 > best_score:\n",
        "    best_score = val_r2\n",
        "    best_grid = g\n",
        "#print(best_grid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnqg2oNtoGuQ",
        "outputId": "4a041052-0522-44e5-a6d1-f06d4cc99302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the model\n",
        "#model = XGBRegressor(colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=600, objective='reg:squarederror')\n",
        "model = XGBRegressor()\n",
        "model.set_params(**best_grid)\n",
        "model = multioutput.MultiOutputRegressor(model)\n",
        "model.fit(X_train, Y_train)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  \"because it will generate extra copies and increase memory consumption\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputRegressor(estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                            colsample_bylevel=1,\n",
              "                                            colsample_bynode=1,\n",
              "                                            colsample_bytree=1, gamma=0,\n",
              "                                            importance_type='gain',\n",
              "                                            learning_rate=0.1, max_delta_step=0,\n",
              "                                            max_depth=5, min_child_weight=1,\n",
              "                                            missing=None, n_estimators=600,\n",
              "                                            n_jobs=1, nthread=None,\n",
              "                                            objective='reg:squarederror',\n",
              "                                            random_state=0, reg_alpha=0,\n",
              "                                            reg_lambda=1, scale_pos_weight=1,\n",
              "                                            seed=None, silent=None, subsample=1,\n",
              "                                            verbosity=1),\n",
              "                     n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvxFZma-oKWT",
        "outputId": "0cca4592-e5aa-4768-8a6b-f8d25fe7a56e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model\n",
        "\n",
        "## Training\n",
        "y_predTrain = pd.DataFrame(model.predict(X_train))\n",
        "y_predTrain[1] = np.clip(y_predTrain[1], a_min=0, a_max=None)\n",
        "\n",
        "ss_train_r2 = r2_score(Y_train[:,0], y_predTrain[0])\n",
        "ss_train_rmse = np.sqrt(mean_squared_error(Y_train[:,0], y_predTrain[0]))\n",
        "\n",
        "ttf_train_r2 = r2_score(Y_train[:,1], y_predTrain[1])\n",
        "ttf_train_rmse = np.sqrt(mean_squared_error(Y_train[:,1], y_predTrain[1]))\n",
        "\n",
        "\n",
        "## Val\n",
        "y_predVal = pd.DataFrame(model.predict(X_val))\n",
        "y_predVal[1] = np.clip(y_predVal[1], a_min=0, a_max=None)\n",
        "\n",
        "ss_val_r2 = r2_score(Y_val[:,0], y_predVal[0])\n",
        "ss_val_rmse = np.sqrt(mean_squared_error(Y_val[:,0], y_predVal[0]))\n",
        "\n",
        "ttf_val_r2 = r2_score(Y_val[:,1], y_predVal[1])\n",
        "ttf_val_rmse = np.sqrt(mean_squared_error(Y_val[:,1], y_predVal[1]))\n",
        "\n",
        "## Testing\n",
        "y_predTest = pd.DataFrame(model.predict(x_test))\n",
        "y_predTest[1] = np.clip(y_predTest[1], a_min=0, a_max=None)\n",
        "\n",
        "ss_test_r2 = r2_score(y_test[:,0], y_predTest[0])\n",
        "ss_test_rmse = np.sqrt(mean_squared_error(y_test[:,0], y_predTest[0]))\n",
        "\n",
        "ttf_test_r2 = r2_score(y_test[:,1], y_predTest[1])\n",
        "ttf_test_rmse = np.sqrt(mean_squared_error(y_test[:,1], y_predTest[1]))\n",
        "\n",
        "\n",
        "print('Shear Stress')\n",
        "print('R2 score:', ss_train_r2, ss_val_r2, ss_test_r2, '\\nRMSE:', ss_train_rmse, ss_val_rmse, ss_test_rmse)\n",
        "print('\\nTTF')\n",
        "print('R2 score:', ttf_train_r2, ttf_val_r2, ttf_test_r2, '\\nRMSE:', ttf_train_rmse, ttf_val_rmse, ttf_test_rmse)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shear Stress\n",
            "R2 score: 0.9969209150802087 0.9591462889799628 0.8882204021216867 \n",
            "RMSE: 0.007133119102595848 0.029823592893577253 0.04830921658847603\n",
            "\n",
            "TTF\n",
            "R2 score: 0.9934169039503822 0.9130198332691188 0.8317145278233581 \n",
            "RMSE: 0.08504539075208456 0.3399725651345053 0.47107362426972393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bij8_XvOjYJL"
      },
      "source": [
        "# Save the predictions\n",
        "'''\n",
        "hf = h5py.File('/content/drive/My Drive/Colab Notebooks/Labquake_prediction/MLpreprocessed_code/predictions/xgb_mo.h5', 'w')\n",
        "g1 = hf.create_group('ss')\n",
        "g1.create_dataset('y_predTrain', data=y_predTrain[0])\n",
        "g1.create_dataset('y_predTest', data=y_predTest[0])\n",
        "\n",
        "g2 = hf.create_group('ttf')\n",
        "g2.create_dataset('y_predTrain', data=y_predTrain[1])\n",
        "g2.create_dataset('y_predTest', data=y_predTest[1])\n",
        "hf.close()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raRHXt5TKLFL"
      },
      "source": [
        "# Overall plot\n",
        "\n",
        "ttime = df1['Time'][n_steps:]\n",
        "traintime, testtime = train_test_split(ttime, test_size=0.3, shuffle=False)\n",
        "\n",
        "## SS plot\n",
        "fig = plt.figure(1, figsize=(20,6))\n",
        "plt.plot(ttime, ydf['SS'])\n",
        "plt.plot(traintime, y_predTrain[0])\n",
        "plt.plot(testtime, y_predTest[0], 'tab:red')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Shear Stress (MPa)')\n",
        "plt.text(ttime.iloc[0], 5.3, 'Test R2 Score: %0.5f' %(ss_test_r2), style='italic', bbox=dict(facecolor='red', alpha=0.5, pad=10))\n",
        "plt.legend(['Ground truth', 'Train Prediction', 'Test Prediction'])\n",
        "plt.title('Shear Stress prediction using multioutput XGBoost model')\n",
        "\n",
        "## TTF plot\n",
        "fig = plt.figure(2, figsize=(20,6))\n",
        "plt.plot(ttime, ydf['TTF'])\n",
        "plt.plot(traintime, y_predTrain[1])\n",
        "plt.plot(testtime, y_predTest[1], 'tab:red')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('TTF (s)')\n",
        "plt.text(ttime.iloc[10000], 4.2, 'Test R2 Score: %0.5f' %(ttf_test_r2), style='italic', bbox=dict(facecolor='red', alpha=0.5, pad=10))\n",
        "plt.legend(['Ground truth', 'Train Prediction', 'Test Prediction'])\n",
        "plt.title('Time to Failure prediction using multioutput XGBoost model')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfV-0hdGM9Nm"
      },
      "source": [
        "# Detailed plot (test data)\n",
        "\n",
        "n = 4000\n",
        "st_i = 3200\n",
        "\n",
        "## SS\n",
        "fig = plt.figure(6, figsize=(20,6))\n",
        "plt.plot(testtime[st_i:st_i+n], y_test['SS'][st_i:st_i+n])\n",
        "plt.plot(testtime[st_i:st_i+n], y_predTest[0][st_i:st_i+n], 'r')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Shear Stress (MPa)')\n",
        "plt.legend(['Ground truth', 'Predicted'])\n",
        "plt.title('Detailed View, Testing Data')\n",
        "\n",
        "## TTF\n",
        "fig = plt.figure(7, figsize=(20,6))\n",
        "plt.plot(testtime[st_i:st_i+n], y_test['TTF'][st_i:st_i+n])\n",
        "plt.plot(testtime[st_i:st_i+n], y_predTest[1][st_i:st_i+n], 'r')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Shear Stress (MPa)')\n",
        "plt.legend(['Ground truth', 'Predicted'])\n",
        "plt.title('Detailed View, Testing Data')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}